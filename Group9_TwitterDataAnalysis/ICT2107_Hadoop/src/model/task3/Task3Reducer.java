package model.task3;
import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

/************************************************************************************************
 * Developer: Winnie	  																		*
 * 																								*
 * Date: 03 April 2016  																		*
 * 																								*
 * Description: This class reads the input sent over from the mapper class. It processes the    *
                intermediate value for the key generated by the mapper. 		             	*
 ************************************************************************************************/
public class Task3Reducer extends Reducer<Text, IntWritable, Text, IntWritable> {
	
	/************************************************************************************************
	 * Description: Firstly, we implement a counter to count the number of rows that matches the 	*
	 * 				query.																			*
	 ************************************************************************************************/
	@Override
	protected void reduce(Text key, Iterable<IntWritable> values,
			Reducer<Text, IntWritable, Text, IntWritable>.Context context) throws IOException, InterruptedException {
		
		int count = 0;
		
		/************************************************************************************************
		 * Description: For every value that matches the query, we implement the counter by 1.  		*
		 * 																								*
		 ************************************************************************************************/
		for (IntWritable value: values) {
			
			count+=value.get();
		}
		
		context.write(key, new IntWritable(count));
	}
}

